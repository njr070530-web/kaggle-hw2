import torch
import torch.nn as nn
import torch.nn.functional as F
import pandas as pd
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import os
import random
from PIL import Image
from sklearn.model_selection import train_test_split
import time
from models import Net
from models import get_pretrained_model


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
if torch.cuda.is_available():
    print(f'trainig on :{torch.cuda.get_device_name(0)}')
else:
    print('training on : CPU')

# ... import éƒ¨åˆ†ä¿æŒä¸å˜ ...

# 1. å®šä¹‰ä¸¤ä¸ª transform
# è®­ç»ƒç”¨ï¼šèŠ±é‡Œèƒ¡å“¨ï¼Œå¢å¼ºæ³›åŒ–
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=15),
    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# éªŒè¯ç”¨ï¼šè€è€å®å®ï¼Œåªåšæ ‡å‡†åŒ–
val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# 2. âš ï¸ å…³é”®ä¿®æ”¹ï¼šå…ˆæ‹†åˆ†æ•°æ®ï¼Œå†åˆ†åˆ«åˆ›å»º Dataset
# æˆ‘ä»¬å…ˆè¯»å–ä¸€æ¬¡ CSV æ¥åš split
full_df = pd.read_csv("data/raw/trainval.csv", header=None, skiprows=1)
# åªè¦ç´¢å¼•ï¼Œä¸éœ€è¦æ•°æ®
indices = list(range(len(full_df)))
train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=0)

# åˆ©ç”¨ Subset æˆ–è€…é‡æ–°å®ç° Dataset æ¥åŒºåˆ† transform
# ä¸ºäº†ä¸æ”¹åŠ¨ä½ çš„ MyDataset ç±»ç»“æ„ï¼Œæœ€ç®€å•çš„åŠæ³•æ˜¯å®ä¾‹åŒ–ä¸¤æ¬¡ï¼Œä½†ä¼ å…¥ä¸åŒçš„ indicesï¼ˆéœ€è¦ç¨å¾®æ”¹ä¸‹ Datasetï¼‰
# æˆ–è€…æ›´ç²—æš´çš„æ–¹æ³•ï¼ˆä¸æ”¹ Dataset ç±»ï¼‰ï¼š

class MyDataset(Dataset):
    def __init__(self, root, csv_file, mode='train', transform=None, indices=None):
        self.root = root
        self.transforms = transform
        df_all = pd.read_csv(csv_file, header=None, skiprows=1)
        
        # âœ… å¦‚æœä¼ å…¥äº† indicesï¼Œå°±åªå–è¿™éƒ¨åˆ†
        if indices is not None:
            self.df = df_all.iloc[indices, :].reset_index(drop=True)
        else:
            self.df = df_all
            
        self.classes = sorted(df_all[1].unique()) # è¿™ä¸€æ­¥è¦å°å¿ƒï¼Œå¿…é¡»ç”¨å…¨é›†ç®— classes
        self.mode = mode # è®°å½•æ¨¡å¼

    def __len__(self):
        return len(self.df)

    def __getitem__(self, index):
        vid, label = self.df.iloc[index, :]
        img_list = sorted(os.listdir(os.path.join(self.root, f"{vid}")))

        # âœ… é€»è¾‘ä¿®æ­£ï¼š
        # åªæœ‰åœ¨ mode='train' ä¸”æœ‰ transform æ—¶æ‰éšæœºæŠ½
        if self.mode == 'train':
            idx = random.randint(0, len(img_list) - 1)
        else:
            # val å’Œ test æ°¸è¿œå–ä¸­é—´
            idx = int(len(img_list) / 2)
            
        img_path = os.path.join(self.root, f"{vid}", img_list[idx])
        img = Image.open(img_path).convert('RGB')
        
        if self.transforms is not None:
            img = self.transforms(img)

        label = self.classes.index(label)
        return img, label

# 3. å®ä¾‹åŒ–æ•°æ®é›† (ä¿®å¤æ•°æ®æ³„éœ²é—®é¢˜)
train_dataset = MyDataset("data/frames/video_frames_30fpv_320p", "data/raw/trainval.csv", 
                          mode='train', transform=train_transform, indices=train_idx)

val_dataset = MyDataset("data/frames/video_frames_30fpv_320p", "data/raw/trainval.csv", 
                        mode='val', transform=val_transform, indices=val_idx)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)

# ... æ¨¡å‹åŠ è½½éƒ¨åˆ†ä¸å˜ ...
num_classes = len(train_dataset.classes)
net = get_pretrained_model(num_classes=num_classes, freeze_backbone=True).to(device)

# 4. ğŸš€ åˆå§‹å‚æ•°è°ƒæ•´ (Stage 1)
# Weight Decay é™ä¸º 1e-4ï¼Œé˜²æ­¢æ¬ æ‹Ÿåˆ
optimizer = torch.optim.SGD(filter(lambda p:p.requires_grad, net.parameters()),
                            lr=0.005, momentum=0.9, weight_decay=1e-4) 

scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

UNFREEZE_EPOCH = 5 # å»ºè®®æ”¹ä¸º 5ï¼ŒResNet æ²¡å¿…è¦å†»ç»“é‚£ä¹ˆä¹…
best_acc = 0.0

for epoch in range(50):
    # ... å‰é¢ä»£ç ä¸å˜ ...
    t0 = time.time()
    
    if epoch == UNFREEZE_EPOCH:
        print("ğŸ”“ è§£å†»æ‰€æœ‰å±‚ï¼Œå¼€å§‹å¾®è°ƒæ•´ä¸ªæ¨¡å‹...")
        for param in net.parameters():
            param.requires_grad = True
            
        # 5. ğŸš€ è§£å†»å‚æ•°è°ƒæ•´ (Stage 2 - å…³é”®ï¼)
        optimizer = torch.optim.SGD([
            # Backbone ç»´æŒ 1e-4 ä¸å˜ (ResNet å±‚)
            {'params': net.conv1.parameters(), 'lr': 1e-4},
            {'params': net.bn1.parameters(),   'lr': 1e-4},
            {'params': net.layer1.parameters(), 'lr': 1e-4},
            {'params': net.layer2.parameters(), 'lr': 1e-4},
            {'params': net.layer3.parameters(), 'lr': 1e-4},
            {'params': net.layer4.parameters(), 'lr': 1e-4},
            
            # âš ï¸ FC å±‚æé«˜åˆ° 1e-3 (0.001)ï¼ä¸è¦ç”¨ 0.0001ï¼Œå¤ªå°äº†ï¼
            {'params': net.fc.parameters(),    'lr': 1e-3} 
        ], momentum=0.9, weight_decay=1e-4) # ç»Ÿä¸€ Weight Decay
        
        # é‡ç½® Schedulerï¼Œç»™å®ƒæœºä¼šé‡æ–°è¡°å‡
        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
    
    # ... åé¢çš„è®­ç»ƒå¾ªç¯ä¸å˜ ...
    net.train()
    running_loss=0.0

    for i, (inputs, labels) in enumerate(train_loader, 0):
        inputs = inputs.to(device, non_blocking=True)
        labels = labels.to(device, non_blocking=True)
        outputs=net(inputs)
        loss=criterion(outputs,labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        if (i + 1) % 100 == 0:
            avg_loss = running_loss / 100
            print(f"Epoch [{epoch+1}/50], Step [{i+1}/{len(train_loader)}], Loss: {avg_loss:.4f}")
            running_loss = 0.0
            current_lr = optimizer.param_groups[-1]['lr'] 
            print(f"Epoch {epoch+1} done. Current FC LR: {current_lr}")
        # Training code ...
    
    scheduler.step()
    net.eval()
    correct=0
    total=0
    with torch.no_grad():
        for val_inputs, val_labels in val_loader:
            val_inputs, val_labels= val_inputs.to(device), val_labels.to(device)
            outputs=net(val_inputs)
            predicted=outputs.argmax(dim=1)
            total+=val_labels.size(0)
            correct+=(predicted==val_labels).sum().item()
    t1=time.time()
    acc = 100 * correct / total
    print(f"â±ï¸  è®­ç»ƒæ—¶é—´: {t1 - t0:.2f} ç§’")
    print(f"ğŸ”¥ æµ‹è¯•é›†å‡†ç¡®ç‡: {100 * correct / total:.2f}%")

    if acc > best_acc:
        best_acc = acc
        torch.save(net.state_dict(), 'model_best.pth')
        print(f"ğŸ† æ–°çºªå½•ï¼æ¨¡å‹å·²ä¿å­˜ (Acc: {best_acc:.2f}%)")

            # Validation code ...


    torch.save(net.state_dict(), 'model_last.pth')
